# IDS
## Weak 1( Introduction to Data Science )

In this week I theory learned the basic of data Science such as 
### what is Data Science:
In this section i learned the basic defination of data science and the key elements of Data Science such as (Machine learning, statistical analysis, Data visualization, and data-
driven decision making)

### The importance of Data Science:
In this Section i learned why data science is important and some industries that uses Data science such as ( Health care,finance, marketing, and technology )

### Data Science Process:
Hear i learnd about the Data collention Process Steps.
* Data collention.
* Data cleaning and processing.  
* Statistical analysis and modeling.
* Machine learning and predictive modeling.
* Data visualization and communication.
* Developing data-driven solutions to real-world problems.
The process is iterative and involves going back and forth between different steps as necessary
### Data Science Tools and Technologies:
i learned about the different tools which are used in the data Science filed such as programiming language, librarys, modeling tools and frameworks.
### Data Science Skills:
The Skills require for Data Science are borblem solving, programiming, Data modeling and statistical.

## weak 2 (Introduction to python)
In this weak we learnded how to write basic python commands and learned the use of 
* Functions
* Types and sequences
* Strings
* Reading and writing CVS Files
* Using Dates and Times
* Objects and Map()
* Lambda and List Comprehensions

### Introduction to Numpy:
Numpy is the fundamental package for numeric computing with python. it provides powerful ways to create store and manipilate data. In this lecture we learned how to:
* Create Arrays.
* Selecting Elements from Arrays.
* Loading dataset into an array.
Numpy array is same as python dictionary but the main differences is that it is faster and provide bultin function that make our work easy.
## Weak 3 (Data Types and Sources)
### Data:
 Data is raw fact and figures that do not convay any infromation on its own. same data can convay different meaning accouding to its Types. 
 ###Data Types
 There are two types of data
 #### Quantitative data:
 This type data is numaric in nature which is divided in to two parts 
 * continues data
 * discreate data.

 #### Qualitative data:
 This type of data is discriptive in nature and is also divided into two parts.
 * nominal data
 * ordinal data

## Weak 4 (Data Cleaning and Preprocessing)
### Scaling
scaling is used to con vert data with differen values or scale in to the same scale. 
some types of scales are :
* min max scale
* standard scale
### mearging
some time when we are working with data we have data in two different files or table in that case we want to mearge the files

### Pivot Tables

A pivot table is a way of summarizing data in a DataFrame for a particular purpose. It makes heavy use of the aggregation function. A pivot table is itself a DataFrame, where the rows represent one variable that you're interested in, the columns another, and the cell's some aggregate value. A pivot table also tends to includes marginal values as well, which are the sums for each column and row. This allows you to be able to see the relationship between two variables at just a glance.
### synatx 
df.pivot_table(values='score', index='country', columns='Rank_Level', aggfunc=[np.mean]).head();

parameters:
* Data
* Value 
* index
* column
### Aggfunct():
These are list of numpy function that we can use to aggregate out piviot table. the defauly aggregate argument function mean.

## Weak 5 (Exploratory Data Analysis (EDA))
EDA is an approch thst is used to analuze the data and discover trends, patteren or checks assumption in data with help of ststistical summaries and graphical representations.
### Types of EDA
 Depending on the number of columns we are analayze or dealing with we divide EDA into Two types:
 * Univariate Analysis
 * Multivariate Analysis
## weak 6(Types of Charts and Graphs)
 Data visualization techniques using the ggplot module in Python. The notebooks walk through the process of reading and exploring the gapminder dataset using pandas, followed by creating various plots such as scatter plots, line plots, box plots, histograms, and density plots using ggplot. Additionally, it covers customization options like log transformations, color palettes, faceting, and theme adjustments. The code serves as a beginner's guide to using Jupyter Notebooks and ggplot for creating insightful and visually appealing plots with real-world data.
 ## weak 7 (Tools for Data Visualization)
 It covers popular data visualization libraries in different programming languages like Python (e.g., Matplotlib, Seaborn, Plotly, ggplot), R (e.g., ggplot2, lattice), and JavaScript (e.g., D3.js, Plotly.js). Each tool's capabilities and examples of their usage are provided through Jupyter Notebooks, R Markdown files, and web-based demos.
 ## weak 8 (Statistical Inference)
It covers fundamental concepts such as hypothesis testing, confidence intervals, p-values, and statistical significance. The provided Jupyter Notebooks and R scripts demonstrate practical applications of statistical inference using real-world datasets. Whether you're a beginner or experienced data scientist, this repository equips you with the knowledge and tools to make data-driven decisions
 ## weak 9 (Introduction to Machine Learning)
Machine Learning is a branch of artificial intelligence that focuses on developing algorithms and models that enable computers to learn from data and improve their performance on specific tasks without being explicitly programmed. It is a powerful and versatile field with applications in various domains, including data analysis, pattern recognition, image and speech processing, natural language understanding, and more.
There are two primary types of machine learning:
* Supervised Learning.
* Unsupervised Learning.
 ## weak 10 (Regression Analysis)
Regression analysis is a statistical method used to examine the relationship between one or more independent variables (predictors) and a dependent variable (outcome). It aims to model and predict the value of the dependent variable based on the values of the independent variables.
## weak 11 (Classification Analysis)
Classification analysis is a statistical and machine learning method used to categorize or classify data into predefined classes or categories based on their features or attributes. It is one of the most common and important tasks in supervised learning, where the algorithm learns from labeled training data to make predictions on new, unseen data.

In classification analysis, the data consists of a set of input variables (features) and a target variable (class or category). The goal is to build a model that can accurately assign each data point to its correct class based on the input features. The target variable can be binary (two classes) or multiclass (more than two classes).

## weak 12 (Decision Trees and Random Forest)
Decision Trees and Random Forest are powerful machine learning algorithms used for both regression and classification tasks. They are part of the family of ensemble learning methods, which combine multiple individual models to make more accurate and robust predictions

## weak 13 (Unsupervised Learning: Clustering Analysis)
Unsupervised learning is a branch of machine learning where the algorithm is trained on unlabeled data, and its goal is to discover patterns, relationships, or structures within the data without explicit guidance on the target outcome. Clustering analysis is a common type of unsupervised learning, where the algorithm groups similar data points into clusters based on their similarities.
## weak 14 (Unsupervised Learning: Dimensionality Reduction)
Dimensionality reduction is a technique in unsupervised learning that aims to reduce the number of features (dimensions) in a high-dimensional dataset while preserving its essential characteristics and minimizing the loss of information. It is particularly useful when dealing with datasets with a large number of features, as reducing dimensionality can lead to more efficient computation and better visualization of the data.

## weak 15 (Big Data and Databases for Data Science)
Big Data refers to large and complex datasets that are too large to be processed and analyzed using traditional data processing techniques. These datasets typically have high volume, velocity, and variety, and they often require specialized tools and technologies for storage, processing, and analysis.

## weak 16 (Ethics in Applied Data Science)
Ethics in applied data science refers to the responsible and ethical use of data, algorithms, and machine learning models in real-world applications. As data science becomes increasingly pervasive across various industries and domains, ethical considerations are paramount to ensure that data-driven decisions do not lead to harmful or biased outcomes.
## Assignment No 1
[https://github.com/MohibUllah11224/Assignment-No-1]
## Assignment No 2
[https://github.com/MohibUllah11224/Assignment-NO-2]
## Assignment No 3
[https://github.com/MohibUllah11224/Assignment-NO-3]
